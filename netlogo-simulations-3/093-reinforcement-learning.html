<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reinforcement Learning - CCAB</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: #1a1a2e; color: #e8e6e1; overflow: hidden; }
        #container { display: flex; height: 100vh; }
        #main-area { flex: 1; display: flex; flex-direction: column; padding: 20px; gap: 15px; }
        canvas { background: rgba(0,0,0,0.3); border-radius: 8px; flex: 1; }
        #controls { width: 300px; background: rgba(0,0,0,0.8); padding: 20px; overflow-y: auto; }
        h1 { font-size: 1.2rem; margin-bottom: 10px; color: #fbbf24; }
        .description { font-size: 0.75rem; color: #888; margin-bottom: 15px; line-height: 1.4; }
        .control-group { margin-bottom: 15px; }
        label { display: block; font-size: 0.8rem; margin-bottom: 5px; color: #aaa; }
        input[type="range"] { width: 100%; margin-bottom: 5px; }
        .value-display { font-size: 0.75rem; color: #fbbf24; }
        button { width: 100%; padding: 10px; margin-bottom: 10px; background: #fbbf24; color: #1a1a2e; border: none; border-radius: 5px; cursor: pointer; font-weight: bold; }
        button:hover { background: #f59e0b; }
        .stats { background: rgba(255,255,255,0.1); padding: 10px; border-radius: 5px; font-size: 0.8rem; margin-top: 15px; }
        .stats div { margin-bottom: 5px; }
        .stats span { color: #fbbf24; }
        .back-link { position: fixed; top: 10px; left: 10px; padding: 8px 16px; background: rgba(0,0,0,0.7); color: #fbbf24; text-decoration: none; border-radius: 6px; font-size: 14px; z-index: 999; }
        .theory { background: rgba(251,191,36,0.1); padding: 10px; border-radius: 5px; font-size: 0.7rem; margin-top: 15px; border-left: 3px solid #fbbf24; }
    </style>
</head>
<body>
    <a href="../netlogo-simulations/index.html" class="back-link">‚Üê Back to Simulations</a>

    <div id="container">
        <div id="main-area">
            <canvas id="canvas"></canvas>
        </div>

        <div id="controls">
            <h1>üéØ Reinforcement Learning</h1>
            <p class="description">
                Agent learns optimal behavior through trial and error. Uses Q-learning
                to navigate a grid world, maximizing rewards while avoiding penalties.
            </p>

            <div class="control-group">
                <label>Learning Rate (Œ±): <span class="value-display" id="alphaValue">0.5</span></label>
                <input type="range" id="alphaSlider" min="0.1" max="1" step="0.1" value="0.5">
            </div>

            <div class="control-group">
                <label>Discount (Œ≥): <span class="value-display" id="gammaValue">0.9</span></label>
                <input type="range" id="gammaSlider" min="0.5" max="0.99" step="0.01" value="0.9">
            </div>

            <div class="control-group">
                <label>Exploration (Œµ): <span class="value-display" id="epsilonValue">0.3</span></label>
                <input type="range" id="epsilonSlider" min="0" max="0.5" step="0.05" value="0.3">
            </div>

            <button id="startBtn">Start Learning</button>
            <button id="resetBtn">Reset</button>

            <div class="stats">
                <div>Generation: <span id="generation">0</span></div>
                <div>Episodes: <span id="episodes">0</span></div>
                <div>Total Reward: <span id="reward">0</span></div>
                <div>Avg Steps: <span id="avgSteps">0</span></div>
                <div>Success Rate: <span id="success">0%</span></div>
            </div>

            <div class="theory">
                <strong>Q-Learning:</strong><br>
                ‚Ä¢ Q(s,a) ‚Üê Q(s,a) + Œ±[r + Œ≥ max Q(s',a') - Q(s,a)]<br>
                ‚Ä¢ <b>Œ±:</b> Learning rate<br>
                ‚Ä¢ <b>Œ≥:</b> Future reward discount<br>
                ‚Ä¢ <b>Œµ:</b> Exploration vs exploitation
            </div>
        </div>
    </div>

    <script>
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');

        function resize() {
            canvas.width = canvas.parentElement.clientWidth - 15;
            canvas.height = canvas.parentElement.clientHeight - 15;
        }
        resize();
        window.addEventListener('resize', resize);

        let running = false;
        let generation = 0;

        let alpha = 0.5;  // Learning rate
        let gamma = 0.9;  // Discount factor
        let epsilon = 0.3; // Exploration rate

        const GRID_SIZE = 6;
        const ACTIONS = ['up', 'down', 'left', 'right'];

        let grid = [];
        let qTable = {};
        let agent = { x: 0, y: 0 };
        let goal = { x: 5, y: 5 };
        let obstacles = [];
        let episodes = 0;
        let episodeSteps = 0;
        let totalReward = 0;
        let rewardHistory = [];
        let stepsHistory = [];
        let successCount = 0;

        function initGrid() {
            grid = [];
            for (let y = 0; y < GRID_SIZE; y++) {
                grid[y] = [];
                for (let x = 0; x < GRID_SIZE; x++) {
                    grid[y][x] = 0; // Empty
                }
            }

            // Goal
            grid[goal.y][goal.x] = 2;

            // Obstacles
            obstacles = [
                { x: 2, y: 1 }, { x: 2, y: 2 }, { x: 2, y: 3 },
                { x: 4, y: 3 }, { x: 4, y: 4 }
            ];
            obstacles.forEach(o => {
                grid[o.y][o.x] = -1;
            });

            // Initialize Q-table
            qTable = {};
            for (let y = 0; y < GRID_SIZE; y++) {
                for (let x = 0; x < GRID_SIZE; x++) {
                    const state = `${x},${y}`;
                    qTable[state] = {};
                    ACTIONS.forEach(a => {
                        qTable[state][a] = 0;
                    });
                }
            }

            resetEpisode();
        }

        function resetEpisode() {
            agent = { x: 0, y: 0 };
            episodeSteps = 0;
        }

        function getState() {
            return `${agent.x},${agent.y}`;
        }

        function getReward(x, y) {
            if (x === goal.x && y === goal.y) return 100;
            if (grid[y] && grid[y][x] === -1) return -50;
            return -1; // Step cost
        }

        function isValid(x, y) {
            return x >= 0 && x < GRID_SIZE && y >= 0 && y < GRID_SIZE && grid[y][x] !== -1;
        }

        function chooseAction(state) {
            // Epsilon-greedy
            if (Math.random() < epsilon) {
                return ACTIONS[Math.floor(Math.random() * ACTIONS.length)];
            }

            // Greedy
            let bestAction = ACTIONS[0];
            let bestQ = qTable[state][bestAction];
            ACTIONS.forEach(a => {
                if (qTable[state][a] > bestQ) {
                    bestQ = qTable[state][a];
                    bestAction = a;
                }
            });
            return bestAction;
        }

        function takeAction(action) {
            let nx = agent.x;
            let ny = agent.y;

            switch (action) {
                case 'up': ny--; break;
                case 'down': ny++; break;
                case 'left': nx--; break;
                case 'right': nx++; break;
            }

            if (isValid(nx, ny)) {
                agent.x = nx;
                agent.y = ny;
            }

            return getReward(agent.x, agent.y);
        }

        function update() {
            if (!running) return;

            generation++;
            episodeSteps++;

            const state = getState();
            const action = chooseAction(state);
            const reward = takeAction(action);
            const newState = getState();

            // Q-learning update
            const maxQ = Math.max(...ACTIONS.map(a => qTable[newState][a]));
            qTable[state][action] += alpha * (reward + gamma * maxQ - qTable[state][action]);

            totalReward += reward;

            // Check episode end
            if (agent.x === goal.x && agent.y === goal.y || episodeSteps > 100) {
                episodes++;
                if (agent.x === goal.x && agent.y === goal.y) {
                    successCount++;
                }

                stepsHistory.push(episodeSteps);
                rewardHistory.push(totalReward);
                if (rewardHistory.length > 50) {
                    rewardHistory.shift();
                    stepsHistory.shift();
                }

                totalReward = 0;
                resetEpisode();
            }

            render();
            updateStats();
            requestAnimationFrame(update);
        }

        function render() {
            ctx.fillStyle = 'rgba(26, 26, 46, 1)';
            ctx.fillRect(0, 0, canvas.width, canvas.height);

            // Title
            ctx.fillStyle = '#888';
            ctx.font = '12px sans-serif';
            ctx.fillText('Reinforcement Learning: Q-Learning Grid World', 20, 25);

            drawGrid();
            drawQValues();
            drawLearningGraph();
        }

        function drawGrid() {
            const gridX = 50;
            const gridY = 70;
            const cellSize = Math.min((canvas.width * 0.4) / GRID_SIZE, (canvas.height - 150) / GRID_SIZE);

            for (let y = 0; y < GRID_SIZE; y++) {
                for (let x = 0; x < GRID_SIZE; x++) {
                    const px = gridX + x * cellSize;
                    const py = gridY + y * cellSize;

                    // Cell background
                    if (grid[y][x] === -1) {
                        ctx.fillStyle = '#1f2937';
                    } else if (x === goal.x && y === goal.y) {
                        ctx.fillStyle = '#22c55e';
                    } else {
                        // Color by max Q value
                        const state = `${x},${y}`;
                        const maxQ = Math.max(...ACTIONS.map(a => qTable[state][a]));
                        const intensity = Math.min(Math.max(maxQ / 50, 0), 1);
                        ctx.fillStyle = `hsl(45, ${intensity * 70}%, ${25 + intensity * 30}%)`;
                    }

                    ctx.fillRect(px, py, cellSize - 2, cellSize - 2);

                    // Draw arrows for best action
                    if (grid[y][x] !== -1 && !(x === goal.x && y === goal.y)) {
                        const state = `${x},${y}`;
                        let bestAction = 'up';
                        let bestQ = -Infinity;
                        ACTIONS.forEach(a => {
                            if (qTable[state][a] > bestQ) {
                                bestQ = qTable[state][a];
                                bestAction = a;
                            }
                        });

                        if (bestQ > 0) {
                            const cx = px + cellSize / 2;
                            const cy = py + cellSize / 2;
                            const arrowLen = cellSize * 0.3;

                            ctx.strokeStyle = 'rgba(255, 255, 255, 0.5)';
                            ctx.lineWidth = 2;
                            ctx.beginPath();

                            switch (bestAction) {
                                case 'up':
                                    ctx.moveTo(cx, cy + arrowLen);
                                    ctx.lineTo(cx, cy - arrowLen);
                                    break;
                                case 'down':
                                    ctx.moveTo(cx, cy - arrowLen);
                                    ctx.lineTo(cx, cy + arrowLen);
                                    break;
                                case 'left':
                                    ctx.moveTo(cx + arrowLen, cy);
                                    ctx.lineTo(cx - arrowLen, cy);
                                    break;
                                case 'right':
                                    ctx.moveTo(cx - arrowLen, cy);
                                    ctx.lineTo(cx + arrowLen, cy);
                                    break;
                            }
                            ctx.stroke();
                        }
                    }
                }
            }

            // Draw agent
            const ax = gridX + agent.x * cellSize + cellSize / 2;
            const ay = gridY + agent.y * cellSize + cellSize / 2;

            ctx.fillStyle = '#fbbf24';
            ctx.beginPath();
            ctx.arc(ax, ay, cellSize * 0.3, 0, Math.PI * 2);
            ctx.fill();

            // Draw goal star
            const gx = gridX + goal.x * cellSize + cellSize / 2;
            const gy = gridY + goal.y * cellSize + cellSize / 2;

            ctx.fillStyle = '#fff';
            ctx.font = `${cellSize * 0.5}px sans-serif`;
            ctx.textAlign = 'center';
            ctx.fillText('‚òÖ', gx, gy + cellSize * 0.15);
            ctx.textAlign = 'left';

            // Legend
            ctx.fillStyle = '#888';
            ctx.font = '10px sans-serif';
            ctx.fillText('üü° Agent  ‚≠ê Goal  ‚¨õ Obstacle', gridX, gridY + GRID_SIZE * cellSize + 20);
        }

        function drawQValues() {
            const qx = canvas.width * 0.48;
            const qy = 50;
            const qw = canvas.width * 0.25;
            const qh = canvas.height * 0.4;

            ctx.fillStyle = 'rgba(0,0,0,0.3)';
            ctx.fillRect(qx, qy, qw, qh);

            ctx.fillStyle = '#888';
            ctx.font = '10px sans-serif';
            ctx.fillText('Q-Value Heatmap', qx + 5, qy + 15);

            const cellSize = Math.min((qw - 20) / GRID_SIZE, (qh - 40) / GRID_SIZE);

            for (let y = 0; y < GRID_SIZE; y++) {
                for (let x = 0; x < GRID_SIZE; x++) {
                    const state = `${x},${y}`;
                    const maxQ = Math.max(...ACTIONS.map(a => qTable[state][a]));

                    const hue = maxQ > 0 ? 45 : 0;
                    const sat = Math.abs(maxQ) / 50 * 100;
                    const light = 30 + Math.abs(maxQ) / 50 * 40;

                    ctx.fillStyle = `hsl(${hue}, ${Math.min(sat, 100)}%, ${Math.min(light, 70)}%)`;
                    ctx.fillRect(qx + 10 + x * cellSize, qy + 25 + y * cellSize, cellSize - 1, cellSize - 1);
                }
            }
        }

        function drawLearningGraph() {
            const graphX = canvas.width * 0.48;
            const graphY = canvas.height * 0.5;
            const graphW = canvas.width * 0.48;
            const graphH = canvas.height * 0.35;

            ctx.fillStyle = 'rgba(0,0,0,0.3)';
            ctx.fillRect(graphX, graphY, graphW, graphH);

            ctx.fillStyle = '#888';
            ctx.font = '10px sans-serif';
            ctx.fillText('Learning Progress (Steps per Episode)', graphX + 5, graphY + 15);

            if (stepsHistory.length > 1) {
                const maxSteps = Math.max(...stepsHistory, 10);

                ctx.strokeStyle = '#fbbf24';
                ctx.lineWidth = 2;
                ctx.beginPath();
                stepsHistory.forEach((steps, i) => {
                    const x = graphX + (i / 50) * graphW;
                    const y = graphY + graphH - (steps / maxSteps) * (graphH - 30) - 10;
                    if (i === 0) ctx.moveTo(x, y);
                    else ctx.lineTo(x, y);
                });
                ctx.stroke();

                // Moving average
                if (stepsHistory.length > 5) {
                    ctx.strokeStyle = '#22c55e';
                    ctx.lineWidth = 1.5;
                    ctx.beginPath();
                    for (let i = 4; i < stepsHistory.length; i++) {
                        const avg = stepsHistory.slice(i - 4, i + 1).reduce((a, b) => a + b, 0) / 5;
                        const x = graphX + (i / 50) * graphW;
                        const y = graphY + graphH - (avg / maxSteps) * (graphH - 30) - 10;
                        if (i === 4) ctx.moveTo(x, y);
                        else ctx.lineTo(x, y);
                    }
                    ctx.stroke();
                }
            }

            // Legend
            ctx.fillStyle = '#fbbf24';
            ctx.fillRect(graphX + graphW - 100, graphY + 5, 10, 10);
            ctx.fillStyle = '#888';
            ctx.fillText('Steps', graphX + graphW - 85, graphY + 14);

            ctx.fillStyle = '#22c55e';
            ctx.fillRect(graphX + graphW - 100, graphY + 20, 10, 10);
            ctx.fillText('Avg', graphX + graphW - 85, graphY + 29);
        }

        function updateStats() {
            const avgSteps = stepsHistory.length > 0
                ? (stepsHistory.reduce((a, b) => a + b, 0) / stepsHistory.length).toFixed(1)
                : 0;
            const successRate = episodes > 0 ? Math.round(successCount / episodes * 100) : 0;

            document.getElementById('generation').textContent = generation;
            document.getElementById('episodes').textContent = episodes;
            document.getElementById('reward').textContent = totalReward.toFixed(0);
            document.getElementById('avgSteps').textContent = avgSteps;
            document.getElementById('success').textContent = successRate + '%';
        }

        document.getElementById('alphaSlider').addEventListener('input', (e) => {
            alpha = parseFloat(e.target.value);
            document.getElementById('alphaValue').textContent = alpha.toFixed(1);
        });

        document.getElementById('gammaSlider').addEventListener('input', (e) => {
            gamma = parseFloat(e.target.value);
            document.getElementById('gammaValue').textContent = gamma.toFixed(2);
        });

        document.getElementById('epsilonSlider').addEventListener('input', (e) => {
            epsilon = parseFloat(e.target.value);
            document.getElementById('epsilonValue').textContent = epsilon.toFixed(2);
        });

        document.getElementById('startBtn').addEventListener('click', () => {
            running = !running;
            document.getElementById('startBtn').textContent = running ? 'Pause' : 'Start Learning';
            if (running) update();
        });

        document.getElementById('resetBtn').addEventListener('click', () => {
            running = false;
            generation = 0;
            episodes = 0;
            successCount = 0;
            rewardHistory = [];
            stepsHistory = [];
            document.getElementById('startBtn').textContent = 'Start Learning';
            initGrid();
            render();
            updateStats();
        });

        initGrid();
        render();
        updateStats();
    </script>
</body>
</html>
