<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Petri Arena - Lab & Sandbox</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #e0e0e0;
            overflow: hidden;
        }

        #container {
            display: flex;
            height: 100vh;
        }

        #canvas-container {
            flex: 1;
            position: relative;
            display: flex;
            align-items: center;
            justify-content: center;
            background: #0f0f1e;
        }

        canvas {
            border: 2px solid #667eea;
            box-shadow: 0 0 30px rgba(102, 126, 234, 0.3);
            cursor: crosshair;
        }

        #sidebar {
            width: 320px;
            background: rgba(22, 33, 62, 0.95);
            padding: 20px;
            overflow-y: auto;
            border-left: 1px solid #667eea;
        }

        h1 {
            font-size: 24px;
            color: #667eea;
            margin-bottom: 20px;
            text-align: center;
        }

        .section {
            background: rgba(102, 126, 234, 0.1);
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 15px;
        }

        .section h2 {
            font-size: 16px;
            color: #667eea;
            margin-bottom: 10px;
            border-bottom: 1px solid rgba(102, 126, 234, 0.3);
            padding-bottom: 5px;
        }

        .control-group {
            margin-bottom: 12px;
        }

        label {
            display: block;
            font-size: 12px;
            color: #b0b0b0;
            margin-bottom: 4px;
        }

        input[type="range"] {
            width: 100%;
            height: 4px;
            background: rgba(102, 126, 234, 0.3);
            border-radius: 2px;
            outline: none;
        }

        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            width: 14px;
            height: 14px;
            background: #667eea;
            border-radius: 50%;
            cursor: pointer;
        }

        input[type="number"] {
            width: 100%;
            padding: 6px;
            background: rgba(0, 0, 0, 0.3);
            border: 1px solid rgba(102, 126, 234, 0.3);
            border-radius: 4px;
            color: #e0e0e0;
            font-size: 12px;
        }

        select {
            width: 100%;
            padding: 6px;
            background: rgba(0, 0, 0, 0.3);
            border: 1px solid rgba(102, 126, 234, 0.3);
            border-radius: 4px;
            color: #e0e0e0;
            font-size: 12px;
        }

        .value-display {
            display: inline-block;
            float: right;
            color: #667eea;
            font-weight: bold;
            font-size: 12px;
        }

        button {
            width: 100%;
            padding: 10px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border: none;
            border-radius: 6px;
            color: white;
            font-weight: bold;
            cursor: pointer;
            margin-bottom: 8px;
            transition: transform 0.1s;
        }

        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
        }

        button:active {
            transform: translateY(0);
        }

        button.secondary {
            background: rgba(102, 126, 234, 0.3);
        }

        .metric {
            display: flex;
            justify-content: space-between;
            padding: 6px 0;
            font-size: 12px;
            border-bottom: 1px solid rgba(102, 126, 234, 0.2);
        }

        .metric:last-child {
            border-bottom: none;
        }

        .metric-value {
            color: #667eea;
            font-weight: bold;
        }

        #inspector {
            font-size: 11px;
            line-height: 1.4;
        }

        .inspector-empty {
            color: #666;
            font-style: italic;
        }

        .agent-color {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 2px;
            margin-right: 4px;
            vertical-align: middle;
        }

        .info-text {
            font-size: 11px;
            color: #888;
            line-height: 1.4;
            margin-top: 8px;
        }

        #tooltip {
            position: absolute;
            background: rgba(0, 0, 0, 0.9);
            border: 1px solid #667eea;
            border-radius: 4px;
            padding: 8px;
            font-size: 11px;
            pointer-events: none;
            display: none;
            z-index: 1000;
        }
    </style>
</head>
<body>
    <div id="container">
        <div id="canvas-container">
            <canvas id="canvas"></canvas>
            <div id="tooltip"></div>
        </div>

        <div id="sidebar">
            <h1>ü¶† Petri Arena Lab</h1>

            <div class="section">
                <h2>‚ö° Controls</h2>
                <button id="btnReset">üîÑ Reset Dish</button>
                <button id="btnPlayPause" class="secondary">‚è∏Ô∏è Pause</button>
                <button id="btnStep" class="secondary">‚è≠Ô∏è Step (1 epoch)</button>
            </div>

            <div class="section">
                <h2>üß™ Presets</h2>
                <select id="presetSelect">
                    <option value="duel">1v1 Duel</option>
                    <option value="triangle">Rock-Paper-Scissors (3-way)</option>
                    <option value="nolearning">Learning vs No-Learning</option>
                    <option value="cycles">Cycle Formation (Large Grid)</option>
                    <option value="waves">Chemical Waves</option>
                </select>
                <button id="btnLoadPreset" class="secondary">üì• Load Preset</button>
            </div>

            <div class="section">
                <h2>‚öôÔ∏è Parameters</h2>

                <div class="control-group">
                    <label>Grid Size: <span class="value-display" id="gridSizeValue">64√ó64</span></label>
                    <input type="range" id="gridSize" min="32" max="196" value="64" step="16">
                </div>

                <div class="control-group">
                    <label>Number of Agents: <span class="value-display" id="numAgentsValue">3</span></label>
                    <input type="range" id="numAgents" min="2" max="8" value="3" step="1">
                </div>

                <div class="control-group">
                    <label>Temperature œÑ: <span class="value-display" id="tauValue">0.10</span></label>
                    <input type="range" id="tau" min="0.01" max="1.0" value="0.1" step="0.01">
                    <div class="info-text">Lower = sharper competition</div>
                </div>

                <div class="control-group">
                    <label>Aliveness Œ±: <span class="value-display" id="alphaValue">0.40</span></label>
                    <input type="range" id="alpha" min="0.1" max="0.9" value="0.4" step="0.05">
                    <div class="info-text">Top-2 threshold (paper: ‚âà0.4)</div>
                </div>

                <div class="control-group">
                    <label>Learning Rate: <span class="value-display" id="lrValue">0.001</span></label>
                    <input type="range" id="learningRate" min="0" max="0.01" value="0.001" step="0.0001">
                    <div class="info-text">0 = no learning (static)</div>
                </div>

                <div class="control-group">
                    <label>Update Speed: <span class="value-display" id="speedValue">1</span></label>
                    <input type="range" id="speed" min="1" max="10" value="1" step="1">
                    <div class="info-text">Epochs per frame</div>
                </div>
            </div>

            <div class="section">
                <h2>üìä Metrics</h2>
                <div class="metric">
                    <span>Epoch:</span>
                    <span class="metric-value" id="metricEpoch">0</span>
                </div>
                <div class="metric">
                    <span>Entropy:</span>
                    <span class="metric-value" id="metricEntropy">0.00</span>
                </div>
                <div class="metric">
                    <span>Total Aliveness:</span>
                    <span class="metric-value" id="metricAliveness">0.00</span>
                </div>
                <div class="metric">
                    <span>Agent Dominance:</span>
                    <span class="metric-value" id="metricDominance">-</span>
                </div>
            </div>

            <div class="section">
                <h2>üîç Cell Inspector</h2>
                <div id="inspector" class="inspector-empty">
                    Click on a cell to inspect its state
                </div>
            </div>

            <div class="section">
                <h2>‚ÑπÔ∏è About PD-NCA</h2>
                <div class="info-text">
                    <strong>Petri Dish Neural Cellular Automata</strong> implements the 4-phase step from the research paper:
                    <br><br>
                    1Ô∏è‚É£ <strong>Processing</strong>: Each agent proposes state updates via CNN<br>
                    2Ô∏è‚É£ <strong>Competition</strong>: Attack/defense cosine similarity<br>
                    3Ô∏è‚É£ <strong>Normalization</strong>: Softmax with temperature œÑ<br>
                    4Ô∏è‚É£ <strong>Update</strong>: Weighted combination clipped to [-1,1]<br>
                    <br>
                    Key finding: Learning during simulation (backprop) produces cycles and emergent cooperation, while no-learning settles to boring steady states.
                </div>
            </div>
        </div>
    </div>

    <script>
        // ===================================================================
        // PETRI DISH NEURAL CELLULAR AUTOMATA (PD-NCA) ENGINE
        // Based on: "Petri Dish: A Multi-Agent Learning System"
        // ===================================================================

        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');

        // Simulation state
        let config = {
            gridSize: 64,
            numAgents: 3,
            tau: 0.1,           // Temperature for softmax
            alpha: 0.4,         // Aliveness threshold (Top-2)
            learningRate: 0.001,
            speed: 1,
            Ca: 3,              // Attack channels
            Cd: 3,              // Defense channels
            Ch: 8               // Hidden channels
        };

        let sim = null;
        let running = true;
        let epoch = 0;

        // Agent colors (fixed palette)
        const AGENT_COLORS = [
            [255, 100, 100],   // Red
            [100, 150, 255],   // Blue
            [100, 255, 100],   // Green
            [255, 200, 100],   // Orange
            [200, 100, 255],   // Purple
            [100, 255, 255],   // Cyan
            [255, 255, 100],   // Yellow
            [255, 150, 200]    // Pink
        ];

        const ENV_COLOR = [80, 80, 80];  // Gray for environment

        // ===================================================================
        // PD-NCA SIMULATION CLASS
        // ===================================================================

        class PDNCASimulation {
            constructor(gridSize, numAgents, config) {
                this.W = gridSize;
                this.H = gridSize;
                this.N = numAgents;
                this.config = config;

                const C = config.Ca + config.Cd + config.Ch;
                this.C = C;

                // State: [H, W, C, N+1] where N+1 includes environment
                // We'll use typed arrays for efficiency
                this.state = new Float32Array(this.H * this.W * C * (this.N + 1));
                this.aliveness = new Float32Array(this.H * this.W * (this.N + 1));

                // Initialize agents at random positions with random initial state
                this.initializeState();

                // Agent "networks" - simplified as random projections for this demo
                // In full implementation, these would be learned CNN parameters
                this.agentWeights = [];
                for (let i = 0; i < this.N; i++) {
                    this.agentWeights.push(this.initializeAgentNetwork());
                }

                // Environment network (static)
                this.envWeights = this.initializeAgentNetwork();
            }

            initializeState() {
                // Random initialization for all agents and environment
                for (let i = 0; i < this.state.length; i++) {
                    this.state[i] = (Math.random() * 2 - 1) * 0.1;
                }

                // Initialize aliveness: place each agent in a random region
                const regionSize = Math.floor(this.W / Math.sqrt(this.N + 1));

                for (let y = 0; y < this.H; y++) {
                    for (let x = 0; x < this.W; x++) {
                        const idx = (y * this.W + x) * (this.N + 1);

                        // Start with environment having some presence everywhere
                        this.aliveness[idx + this.N] = 0.3;

                        // Randomly assign primary agent to cells
                        const primaryAgent = Math.floor(Math.random() * this.N);
                        this.aliveness[idx + primaryAgent] = 0.8;
                    }
                }

                this.normalizeAliveness();
            }

            initializeAgentNetwork() {
                // Simplified: 3x3 convolution weights for each channel
                // Real implementation would have full CNN architecture
                const kernelSize = 9; // 3x3
                const weights = new Float32Array(this.C * kernelSize);
                for (let i = 0; i < weights.length; i++) {
                    weights[i] = (Math.random() * 2 - 1) * 0.1;
                }
                return weights;
            }

            getState(x, y, c, agent) {
                if (x < 0 || x >= this.W || y < 0 || y >= this.H) return 0;
                const idx = ((y * this.W + x) * this.C + c) * (this.N + 1) + agent;
                return this.state[idx];
            }

            setState(x, y, c, agent, value) {
                const idx = ((y * this.W + x) * this.C + c) * (this.N + 1) + agent;
                this.state[idx] = value;
            }

            getAliveness(x, y, agent) {
                const idx = (y * this.W + x) * (this.N + 1) + agent;
                return this.aliveness[idx];
            }

            setAliveness(x, y, agent, value) {
                const idx = (y * this.W + x) * (this.N + 1) + agent;
                this.aliveness[idx] = value;
            }

            // ===================================================================
            // 4-PHASE STEP (Core PD-NCA Algorithm)
            // ===================================================================

            step() {
                // Phase 1: PROCESSING - each agent proposes state updates
                const proposals = this.processingPhase();

                // Phase 2: COMPETITION - compute pairwise strengths
                const strengths = this.competitionPhase();

                // Phase 3: NORMALIZATION - softmax with temperature œÑ
                const weights = this.normalizationPhase(strengths);

                // Phase 4: UPDATE - apply weighted updates and clip
                this.updatePhase(proposals, weights);
            }

            processingPhase() {
                // Each agent proposes Œîs based on Moore neighborhood
                const proposals = new Float32Array(this.H * this.W * this.C * (this.N + 1));

                for (let agent = 0; agent <= this.N; agent++) {
                    const weights = agent < this.N ? this.agentWeights[agent] : this.envWeights;

                    for (let y = 0; y < this.H; y++) {
                        for (let x = 0; x < this.W; x++) {
                            // Only propose where alive or adjacent to alive cells
                            const alive = this.getAliveness(x, y, agent);
                            if (alive < 0.01) continue;

                            // Simplified convolution over 3x3 Moore neighborhood
                            for (let c = 0; c < this.C; c++) {
                                let sum = 0;
                                let idx = 0;

                                for (let dy = -1; dy <= 1; dy++) {
                                    for (let dx = -1; dx <= 1; dx++) {
                                        const nx = x + dx;
                                        const ny = y + dy;
                                        const val = this.getState(nx, ny, c, agent);
                                        sum += val * weights[c * 9 + idx];
                                        idx++;
                                    }
                                }

                                // Tanh activation
                                const delta = Math.tanh(sum);
                                const pIdx = ((y * this.W + x) * this.C + c) * (this.N + 1) + agent;
                                proposals[pIdx] = delta;
                            }
                        }
                    }
                }

                return proposals;
            }

            competitionPhase() {
                // Compute pairwise attack/defense strengths using cosine similarity
                const strengths = new Float32Array(this.H * this.W * (this.N + 1) * (this.N + 1));
                const Ca = this.config.Ca;
                const Cd = this.config.Cd;

                for (let y = 0; y < this.H; y++) {
                    for (let x = 0; x < this.W; x++) {
                        for (let i = 0; i <= this.N; i++) {
                            for (let j = 0; j <= this.N; j++) {
                                // Compute strength: attack_i ¬∑ defense_j (cosine similarity)
                                let dotProduct = 0;
                                let normA = 0;
                                let normD = 0;

                                for (let c = 0; c < Ca; c++) {
                                    const a = this.getState(x, y, c, i);
                                    dotProduct += a * a; // Simplified: self-similarity
                                    normA += a * a;
                                }

                                for (let c = Ca; c < Ca + Cd; c++) {
                                    const d = this.getState(x, y, c, j);
                                    normD += d * d;
                                }

                                const norm = Math.sqrt(normA * normD + 1e-8);
                                const strength = norm > 0 ? dotProduct / norm : 0;

                                const sIdx = ((y * this.W + x) * (this.N + 1) + i) * (this.N + 1) + j;
                                strengths[sIdx] = Math.max(0, strength);
                            }
                        }
                    }
                }

                return strengths;
            }

            normalizationPhase(strengths) {
                // Softmax with temperature œÑ to compute weights
                const weights = new Float32Array(this.H * this.W * (this.N + 1));
                const tau = this.config.tau;

                for (let y = 0; y < this.H; y++) {
                    for (let x = 0; x < this.W; x++) {
                        const baseIdx = (y * this.W + x) * (this.N + 1);

                        // Collect strengths for this cell
                        let maxStrength = -Infinity;
                        for (let agent = 0; agent <= this.N; agent++) {
                            const sIdx = baseIdx * (this.N + 1) + agent * (this.N + 1) + agent;
                            maxStrength = Math.max(maxStrength, strengths[sIdx]);
                        }

                        // Softmax
                        let sumExp = 0;
                        const exps = [];

                        for (let agent = 0; agent <= this.N; agent++) {
                            const sIdx = baseIdx * (this.N + 1) + agent * (this.N + 1) + agent;
                            const exp = Math.exp((strengths[sIdx] - maxStrength) / tau);
                            exps.push(exp);
                            sumExp += exp;
                        }

                        for (let agent = 0; agent <= this.N; agent++) {
                            weights[baseIdx + agent] = exps[agent] / (sumExp + 1e-8);
                        }
                    }
                }

                return weights;
            }

            updatePhase(proposals, weights) {
                // Apply weighted combination and clip to [-1, 1]
                for (let y = 0; y < this.H; y++) {
                    for (let x = 0; x < this.W; x++) {
                        for (let c = 0; c < this.C; c++) {
                            let newState = 0;
                            const baseIdx = (y * this.W + x) * (this.N + 1);

                            for (let agent = 0; agent <= this.N; agent++) {
                                const pIdx = ((y * this.W + x) * this.C + c) * (this.N + 1) + agent;
                                const w = weights[baseIdx + agent];
                                newState += w * proposals[pIdx];
                            }

                            // Clip to [-1, 1]
                            newState = Math.max(-1, Math.min(1, newState));

                            // Update all agents' states (weighted by their presence)
                            for (let agent = 0; agent <= this.N; agent++) {
                                const w = weights[baseIdx + agent];
                                if (w > 0.01) {
                                    this.setState(x, y, c, agent, newState * w);
                                }
                            }
                        }
                    }
                }

                // Update aliveness based on competition weights
                this.updateAliveness(weights);
            }

            updateAliveness(weights) {
                // Update aliveness based on competition, maintaining Top-2 with threshold Œ±
                const alpha = this.config.alpha;

                for (let y = 0; y < this.H; y++) {
                    for (let x = 0; x < this.W; x++) {
                        const baseIdx = (y * this.W + x) * (this.N + 1);

                        // Get current weights and sort to find top-2
                        const agentWeights = [];
                        for (let agent = 0; agent <= this.N; agent++) {
                            agentWeights.push({
                                agent: agent,
                                weight: weights[baseIdx + agent]
                            });
                        }
                        agentWeights.sort((a, b) => b.weight - a.weight);

                        // Update aliveness: top-2 get their weights, others decay
                        for (let agent = 0; agent <= this.N; agent++) {
                            const isTop2 = agentWeights[0].agent === agent || agentWeights[1].agent === agent;
                            const w = weights[baseIdx + agent];

                            let newAlive = this.getAliveness(x, y, agent);

                            if (isTop2 && w > alpha) {
                                newAlive = w;
                            } else {
                                newAlive *= 0.95; // Decay
                            }

                            this.setAliveness(x, y, agent, newAlive);
                        }
                    }
                }

                this.normalizeAliveness();
            }

            normalizeAliveness() {
                // Ensure aliveness sums to 1 per cell
                for (let y = 0; y < this.H; y++) {
                    for (let x = 0; x < this.W; x++) {
                        let sum = 0;
                        for (let agent = 0; agent <= this.N; agent++) {
                            sum += this.getAliveness(x, y, agent);
                        }

                        if (sum > 0) {
                            for (let agent = 0; agent <= this.N; agent++) {
                                const a = this.getAliveness(x, y, agent);
                                this.setAliveness(x, y, agent, a / sum);
                            }
                        }
                    }
                }
            }

            // Learning (simplified gradient descent)
            learn() {
                if (this.config.learningRate === 0) return;

                // Simplified: perturb weights slightly toward maximizing aliveness
                for (let i = 0; i < this.N; i++) {
                    const weights = this.agentWeights[i];

                    for (let j = 0; j < weights.length; j++) {
                        // Random gradient (in real implementation, this would be backprop)
                        const grad = (Math.random() * 2 - 1) * 0.01;
                        weights[j] += this.config.learningRate * grad;
                        weights[j] = Math.max(-1, Math.min(1, weights[j]));
                    }
                }
            }
        }

        // ===================================================================
        // VISUALIZATION & UI
        // ===================================================================

        function resizeCanvas() {
            const size = Math.min(
                window.innerWidth - 320 - 40,
                window.innerHeight - 40
            );
            canvas.width = size;
            canvas.height = size;
        }

        function render() {
            if (!sim) return;

            const cellSize = canvas.width / sim.W;

            for (let y = 0; y < sim.H; y++) {
                for (let x = 0; x < sim.W; x++) {
                    // Find dominant agent (argmax aliveness)
                    let maxAlive = 0;
                    let winner = sim.N; // Default to environment

                    for (let agent = 0; agent <= sim.N; agent++) {
                        const alive = sim.getAliveness(x, y, agent);
                        if (alive > maxAlive) {
                            maxAlive = alive;
                            winner = agent;
                        }
                    }

                    // Color based on winner
                    const color = winner < sim.N ? AGENT_COLORS[winner] : ENV_COLOR;
                    const intensity = maxAlive; // Use aliveness as brightness

                    ctx.fillStyle = `rgb(${color[0] * intensity}, ${color[1] * intensity}, ${color[2] * intensity})`;
                    ctx.fillRect(x * cellSize, y * cellSize, cellSize, cellSize);
                }
            }
        }

        function updateMetrics() {
            if (!sim) return;

            // Compute entropy of aliveness distribution
            let entropy = 0;
            for (let y = 0; y < sim.H; y++) {
                for (let x = 0; x < sim.W; x++) {
                    for (let agent = 0; agent <= sim.N; agent++) {
                        const p = sim.getAliveness(x, y, agent);
                        if (p > 0.01) {
                            entropy -= p * Math.log2(p);
                        }
                    }
                }
            }
            entropy /= (sim.H * sim.W);

            // Total aliveness per agent
            const agentAliveness = new Array(sim.N + 1).fill(0);
            for (let y = 0; y < sim.H; y++) {
                for (let x = 0; x < sim.W; x++) {
                    for (let agent = 0; agent <= sim.N; agent++) {
                        agentAliveness[agent] += sim.getAliveness(x, y, agent);
                    }
                }
            }

            const totalAlive = agentAliveness.reduce((a, b) => a + b, 0);

            // Find dominant agent
            let maxIdx = 0;
            for (let i = 1; i <= sim.N; i++) {
                if (agentAliveness[i] > agentAliveness[maxIdx]) {
                    maxIdx = i;
                }
            }
            const dominance = maxIdx < sim.N ? `Agent ${maxIdx + 1}` : 'Environment';

            document.getElementById('metricEpoch').textContent = epoch;
            document.getElementById('metricEntropy').textContent = entropy.toFixed(2);
            document.getElementById('metricAliveness').textContent = totalAlive.toFixed(1);
            document.getElementById('metricDominance').textContent = dominance;
        }

        function animate() {
            if (running && sim) {
                for (let i = 0; i < config.speed; i++) {
                    sim.step();
                    if (config.learningRate > 0) {
                        sim.learn();
                    }
                    epoch++;
                }

                updateMetrics();
            }

            render();
            requestAnimationFrame(animate);
        }

        // ===================================================================
        // CONTROLS
        // ===================================================================

        function resetSimulation() {
            epoch = 0;
            sim = new PDNCASimulation(config.gridSize, config.numAgents, config);
            updateMetrics();
        }

        document.getElementById('btnReset').addEventListener('click', resetSimulation);

        document.getElementById('btnPlayPause').addEventListener('click', function() {
            running = !running;
            this.textContent = running ? '‚è∏Ô∏è Pause' : '‚ñ∂Ô∏è Play';
        });

        document.getElementById('btnStep').addEventListener('click', function() {
            if (sim) {
                sim.step();
                if (config.learningRate > 0) {
                    sim.learn();
                }
                epoch++;
                updateMetrics();
            }
        });

        // Parameter controls
        document.getElementById('gridSize').addEventListener('input', function() {
            config.gridSize = parseInt(this.value);
            document.getElementById('gridSizeValue').textContent = `${config.gridSize}√ó${config.gridSize}`;
        });

        document.getElementById('numAgents').addEventListener('input', function() {
            config.numAgents = parseInt(this.value);
            document.getElementById('numAgentsValue').textContent = config.numAgents;
        });

        document.getElementById('tau').addEventListener('input', function() {
            config.tau = parseFloat(this.value);
            document.getElementById('tauValue').textContent = config.tau.toFixed(2);
            if (sim) sim.config.tau = config.tau;
        });

        document.getElementById('alpha').addEventListener('input', function() {
            config.alpha = parseFloat(this.value);
            document.getElementById('alphaValue').textContent = config.alpha.toFixed(2);
            if (sim) sim.config.alpha = config.alpha;
        });

        document.getElementById('learningRate').addEventListener('input', function() {
            config.learningRate = parseFloat(this.value);
            document.getElementById('lrValue').textContent = config.learningRate.toFixed(4);
            if (sim) sim.config.learningRate = config.learningRate;
        });

        document.getElementById('speed').addEventListener('input', function() {
            config.speed = parseInt(this.value);
            document.getElementById('speedValue').textContent = config.speed;
        });

        // Preset loader
        document.getElementById('btnLoadPreset').addEventListener('click', function() {
            const preset = document.getElementById('presetSelect').value;

            switch(preset) {
                case 'duel':
                    config.numAgents = 2;
                    config.gridSize = 64;
                    config.tau = 0.1;
                    config.alpha = 0.4;
                    config.learningRate = 0.001;
                    break;
                case 'triangle':
                    config.numAgents = 3;
                    config.gridSize = 64;
                    config.tau = 0.15;
                    config.alpha = 0.3;
                    config.learningRate = 0.002;
                    break;
                case 'nolearning':
                    config.numAgents = 3;
                    config.gridSize = 96;
                    config.tau = 0.1;
                    config.alpha = 0.4;
                    config.learningRate = 0; // No learning!
                    break;
                case 'cycles':
                    config.numAgents = 4;
                    config.gridSize = 128;
                    config.tau = 0.2;
                    config.alpha = 0.35;
                    config.learningRate = 0.003;
                    break;
                case 'waves':
                    config.numAgents = 2;
                    config.gridSize = 96;
                    config.tau = 0.25;
                    config.alpha = 0.5;
                    config.learningRate = 0.0005;
                    break;
            }

            // Update UI
            document.getElementById('gridSize').value = config.gridSize;
            document.getElementById('gridSizeValue').textContent = `${config.gridSize}√ó${config.gridSize}`;
            document.getElementById('numAgents').value = config.numAgents;
            document.getElementById('numAgentsValue').textContent = config.numAgents;
            document.getElementById('tau').value = config.tau;
            document.getElementById('tauValue').textContent = config.tau.toFixed(2);
            document.getElementById('alpha').value = config.alpha;
            document.getElementById('alphaValue').textContent = config.alpha.toFixed(2);
            document.getElementById('learningRate').value = config.learningRate;
            document.getElementById('lrValue').textContent = config.learningRate.toFixed(4);

            resetSimulation();
        });

        // Cell inspector
        canvas.addEventListener('click', function(e) {
            if (!sim) return;

            const rect = canvas.getBoundingClientRect();
            const x = Math.floor((e.clientX - rect.left) / canvas.width * sim.W);
            const y = Math.floor((e.clientY - rect.top) / canvas.height * sim.H);

            if (x >= 0 && x < sim.W && y >= 0 && y < sim.H) {
                let html = `<strong>Cell (${x}, ${y})</strong><br><br>`;

                html += '<strong>Aliveness:</strong><br>';
                for (let agent = 0; agent <= sim.N; agent++) {
                    const alive = sim.getAliveness(x, y, agent);
                    const name = agent < sim.N ? `Agent ${agent + 1}` : 'Env';
                    const color = agent < sim.N ? AGENT_COLORS[agent] : ENV_COLOR;
                    html += `<span class="agent-color" style="background:rgb(${color[0]},${color[1]},${color[2]})"></span>`;
                    html += `${name}: ${alive.toFixed(3)}<br>`;
                }

                html += '<br><strong>Channels:</strong><br>';
                const Ca = config.Ca;
                const Cd = config.Cd;

                // Show channels for dominant agent
                let maxAlive = 0;
                let winner = sim.N;
                for (let agent = 0; agent <= sim.N; agent++) {
                    const alive = sim.getAliveness(x, y, agent);
                    if (alive > maxAlive) {
                        maxAlive = alive;
                        winner = agent;
                    }
                }

                html += `<em>Agent ${winner < sim.N ? winner + 1 : 'Env'}:</em><br>`;
                html += `Attack: [`;
                for (let c = 0; c < Ca; c++) {
                    html += sim.getState(x, y, c, winner).toFixed(2);
                    if (c < Ca - 1) html += ', ';
                }
                html += `]<br>Defense: [`;
                for (let c = Ca; c < Ca + Cd; c++) {
                    html += sim.getState(x, y, c, winner).toFixed(2);
                    if (c < Ca + Cd - 1) html += ', ';
                }
                html += `]<br>Hidden: [`;
                for (let c = Ca + Cd; c < Ca + Cd + 3; c++) {
                    html += sim.getState(x, y, c, winner).toFixed(2);
                    if (c < Ca + Cd + 2) html += ', ';
                }
                html += '...]';

                document.getElementById('inspector').innerHTML = html;
                document.getElementById('inspector').classList.remove('inspector-empty');
            }
        });

        // ===================================================================
        // INITIALIZATION
        // ===================================================================

        window.addEventListener('resize', resizeCanvas);
        resizeCanvas();
        resetSimulation();
        animate();

    </script>
</body>
</html>
