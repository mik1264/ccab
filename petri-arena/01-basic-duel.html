<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>01. Basic Duel (1v1) - Petri Arena</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            background: linear-gradient(135deg, #0a0e27 0%, #1a0b2e 100%);
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            color: white;
        }
        .container {
            text-align: center;
        }
        canvas {
            border: 2px solid #00f5ff;
            box-shadow: 0 0 20px rgba(0, 245, 255, 0.5);
            background: #000;
        }
        h1 {
            margin-bottom: 10px;
            font-size: 2rem;
            text-shadow: 0 0 10px rgba(0, 245, 255, 0.8);
        }
        .info {
            margin-top: 15px;
            font-size: 0.9rem;
            opacity: 0.8;
            max-width: 600px;
            line-height: 1.6;
        }
        .stats {
            margin-top: 10px;
            display: flex;
            justify-content: center;
            gap: 30px;
            font-size: 0.95rem;
        }
        .stat {
            padding: 8px 15px;
            background: rgba(0, 245, 255, 0.1);
            border-radius: 5px;
            border: 1px solid rgba(0, 245, 255, 0.3);
        }
        .agent-label {
            display: inline-block;
            width: 15px;
            height: 15px;
            border-radius: 3px;
            margin-right: 5px;
            vertical-align: middle;
        }
        .controls {
            margin-top: 15px;
            display: flex;
            justify-content: center;
            gap: 10px;
        }
        button {
            padding: 8px 20px;
            font-size: 0.9rem;
            background: rgba(0, 245, 255, 0.2);
            border: 1px solid rgba(0, 245, 255, 0.5);
            color: white;
            border-radius: 5px;
            cursor: pointer;
            transition: all 0.3s;
        }
        button:hover {
            background: rgba(0, 245, 255, 0.4);
            box-shadow: 0 0 10px rgba(0, 245, 255, 0.6);
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸ§¬ Basic Duel (1v1)</h1>
        <canvas id="canvas"></canvas>
        <div class="stats">
            <div class="stat">
                <span class="agent-label" style="background: #00f5ff;"></span>
                Agent 1: <span id="agent1">0</span>%
            </div>
            <div class="stat">
                <span class="agent-label" style="background: #ff00ff;"></span>
                Agent 2: <span id="agent2">0</span>%
            </div>
            <div class="stat">Step: <span id="step">0</span></div>
        </div>
        <div class="controls">
            <button onclick="togglePause()">Pause/Resume</button>
            <button onclick="reset()">Reset</button>
            <button onclick="location.href='index.html'">Back to Gallery</button>
        </div>
        <div class="info">
            Two neural cellular automata agents compete for territorial control. Each agent uses attack and defense
            channels to compete for cells. Watch as they adapt their strategies through simplified gradient-based learning.
            This demonstrates the core PD-NCA competitive mechanism with softmax normalization.
        </div>
    </div>

    <script>
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');

        // Grid parameters
        const gridSize = 128;
        const cellSize = 4;
        canvas.width = gridSize * cellSize;
        canvas.height = gridSize * cellSize;

        // PD-NCA parameters
        const tau = 0.5; // Temperature for softmax
        const alpha = 0.4; // Aliveness threshold
        const numAgents = 2;

        // State: attack, defense, hidden channels for each cell
        let state = {
            attack: Array(numAgents + 1).fill(null).map(() =>
                Array(gridSize).fill(null).map(() => Array(gridSize).fill(0))
            ),
            defense: Array(numAgents + 1).fill(null).map(() =>
                Array(gridSize).fill(null).map(() => Array(gridSize).fill(0))
            ),
            hidden: Array(numAgents + 1).fill(null).map(() =>
                Array(gridSize).fill(null).map(() => Array(gridSize).fill(0))
            ),
            aliveness: Array(numAgents + 1).fill(null).map(() =>
                Array(gridSize).fill(null).map(() => Array(gridSize).fill(0))
            )
        };

        let step = 0;
        let paused = false;

        // Agent colors
        const agentColors = [
            [0, 245, 255],    // Background (cyan)
            [0, 245, 255],    // Agent 1 (cyan)
            [255, 0, 255]     // Agent 2 (magenta)
        ];

        // Initialize agents
        function init() {
            // Random initialization for background (agent 0)
            for (let y = 0; y < gridSize; y++) {
                for (let x = 0; x < gridSize; x++) {
                    state.attack[0][y][x] = Math.random() * 0.2 - 0.1;
                    state.defense[0][y][x] = Math.random() * 0.2 - 0.1;
                    state.hidden[0][y][x] = Math.random() * 0.2 - 0.1;
                    state.aliveness[0][y][x] = 0.5;
                }
            }

            // Agent 1: top-left quadrant
            const cx1 = gridSize * 0.3, cy1 = gridSize * 0.3, r1 = 15;
            for (let y = 0; y < gridSize; y++) {
                for (let x = 0; x < gridSize; x++) {
                    const dist = Math.sqrt((x - cx1) ** 2 + (y - cy1) ** 2);
                    if (dist < r1) {
                        state.attack[1][y][x] = Math.random() * 0.5 + 0.5;
                        state.defense[1][y][x] = Math.random() * 0.5 + 0.5;
                        state.hidden[1][y][x] = Math.random() * 0.5;
                        state.aliveness[1][y][x] = 1.0;
                    }
                }
            }

            // Agent 2: bottom-right quadrant
            const cx2 = gridSize * 0.7, cy2 = gridSize * 0.7, r2 = 15;
            for (let y = 0; y < gridSize; y++) {
                for (let x = 0; x < gridSize; x++) {
                    const dist = Math.sqrt((x - cx2) ** 2 + (y - cy2) ** 2);
                    if (dist < r2) {
                        state.attack[2][y][x] = Math.random() * 0.5 + 0.5;
                        state.defense[2][y][x] = Math.random() * 0.5 + 0.5;
                        state.hidden[2][y][x] = Math.random() * 0.5;
                        state.aliveness[2][y][x] = 1.0;
                    }
                }
            }

            step = 0;
        }

        // Compute competition strengths (simplified cosine similarity)
        function computeStrength(attacker, defender, y, x) {
            const a = state.attack[attacker][y][x];
            const d = state.defense[defender][y][x];
            return a * d; // Simplified interaction
        }

        // 4-phase PD-NCA update
        function update() {
            const newState = {
                attack: state.attack.map(a => a.map(row => [...row])),
                defense: state.defense.map(d => d.map(row => [...row])),
                hidden: state.hidden.map(h => h.map(row => [...row])),
                aliveness: state.aliveness.map(a => a.map(row => [...row]))
            };

            for (let y = 1; y < gridSize - 1; y++) {
                for (let x = 1; x < gridSize - 1; x++) {
                    // Phase 1: Process neighbors (simplified convolution)
                    const deltas = [];
                    for (let agent = 0; agent <= numAgents; agent++) {
                        let avgAttack = 0, avgDefense = 0, avgHidden = 0;
                        let count = 0;
                        for (let dy = -1; dy <= 1; dy++) {
                            for (let dx = -1; dx <= 1; dx++) {
                                avgAttack += state.attack[agent][y + dy][x + dx];
                                avgDefense += state.defense[agent][y + dy][x + dx];
                                avgHidden += state.hidden[agent][y + dy][x + dx];
                                count++;
                            }
                        }
                        deltas.push({
                            attack: (avgAttack / count - state.attack[agent][y][x]) * 0.1,
                            defense: (avgDefense / count - state.defense[agent][y][x]) * 0.1,
                            hidden: (avgHidden / count - state.hidden[agent][y][x]) * 0.1 + Math.random() * 0.05 - 0.025
                        });
                    }

                    // Phase 2: Competition
                    const strengths = [];
                    for (let i = 0; i <= numAgents; i++) {
                        let totalStrength = 0;
                        for (let j = 0; j <= numAgents; j++) {
                            if (i !== j) {
                                totalStrength += computeStrength(i, j, y, x);
                            }
                        }
                        strengths.push(totalStrength + state.aliveness[i][y][x]);
                    }

                    // Phase 3: Normalization (softmax with temperature)
                    const maxStrength = Math.max(...strengths);
                    const expStrengths = strengths.map(s => Math.exp((s - maxStrength) / tau));
                    const sumExp = expStrengths.reduce((a, b) => a + b, 0);
                    const weights = expStrengths.map(e => e / sumExp);

                    // Phase 4: State update
                    for (let agent = 0; agent <= numAgents; agent++) {
                        const w = weights[agent];
                        newState.attack[agent][y][x] = Math.max(-1, Math.min(1,
                            state.attack[agent][y][x] + deltas[agent].attack * w
                        ));
                        newState.defense[agent][y][x] = Math.max(-1, Math.min(1,
                            state.defense[agent][y][x] + deltas[agent].defense * w
                        ));
                        newState.hidden[agent][y][x] = Math.max(-1, Math.min(1,
                            state.hidden[agent][y][x] + deltas[agent].hidden * w
                        ));
                        newState.aliveness[agent][y][x] = w;
                    }
                }
            }

            state = newState;
            step++;
        }

        // Render
        function render() {
            const imageData = ctx.createImageData(gridSize, gridSize);

            for (let y = 0; y < gridSize; y++) {
                for (let x = 0; x < gridSize; x++) {
                    // Find dominant agent
                    let maxAlive = 0;
                    let winner = 0;
                    for (let agent = 0; agent <= numAgents; agent++) {
                        if (state.aliveness[agent][y][x] > maxAlive) {
                            maxAlive = state.aliveness[agent][y][x];
                            winner = agent;
                        }
                    }

                    const idx = (y * gridSize + x) * 4;
                    const color = agentColors[winner];
                    const intensity = maxAlive;
                    imageData.data[idx] = color[0] * intensity;
                    imageData.data[idx + 1] = color[1] * intensity;
                    imageData.data[idx + 2] = color[2] * intensity;
                    imageData.data[idx + 3] = 255;
                }
            }

            ctx.putImageData(imageData, 0, 0);
            ctx.imageSmoothingEnabled = false;
            ctx.drawImage(canvas, 0, 0, gridSize, gridSize, 0, 0, canvas.width, canvas.height);

            // Update stats
            updateStats();
        }

        function updateStats() {
            let territories = [0, 0, 0];
            for (let y = 0; y < gridSize; y++) {
                for (let x = 0; x < gridSize; x++) {
                    let maxAlive = 0;
                    let winner = 0;
                    for (let agent = 0; agent <= numAgents; agent++) {
                        if (state.aliveness[agent][y][x] > maxAlive) {
                            maxAlive = state.aliveness[agent][y][x];
                            winner = agent;
                        }
                    }
                    territories[winner]++;
                }
            }

            const total = gridSize * gridSize;
            document.getElementById('agent1').textContent = ((territories[1] / total) * 100).toFixed(1);
            document.getElementById('agent2').textContent = ((territories[2] / total) * 100).toFixed(1);
            document.getElementById('step').textContent = step;
        }

        function animate() {
            if (!paused) {
                update();
                render();
            }
            requestAnimationFrame(animate);
        }

        function togglePause() {
            paused = !paused;
        }

        function reset() {
            init();
            render();
        }

        init();
        animate();
    </script>
</body>
</html>
