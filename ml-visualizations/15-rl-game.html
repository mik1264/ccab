<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reinforcement Learning Game - ML Visualizations - CCAB</title>
    <style>
        body { margin: 0; padding: 20px; background: #0f0f1a; color: #e8e6e1; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; }
        .back-link { display: inline-block; padding: 8px 16px; background: rgba(124, 58, 237, 0.2); color: #a78bfa; text-decoration: none; border-radius: 6px; margin-bottom: 20px; }
        .back-link:hover { background: rgba(124, 58, 237, 0.4); }
        h1 { color: #a78bfa; margin-bottom: 10px; }
        .subtitle { color: #888; margin-bottom: 20px; }
        .container { display: flex; gap: 30px; flex-wrap: wrap; }
        .panel { background: rgba(255,255,255,0.05); border-radius: 12px; padding: 20px; }
        canvas { border-radius: 8px; }
        button { background: #7C3AED; color: white; border: none; padding: 10px 20px; border-radius: 6px; cursor: pointer; margin: 5px; }
        button:hover { background: #6D28D9; }
        button:disabled { background: #4a4a5a; }
        select { background: #1a1a2e; color: #e8e6e1; padding: 10px; border-radius: 6px; border: 1px solid #7C3AED; margin: 5px; }
        .stats { display: grid; grid-template-columns: repeat(2, 1fr); gap: 15px; margin-top: 15px; }
        .stat { background: rgba(255,255,255,0.05); border-radius: 8px; padding: 15px; text-align: center; }
        .stat-value { font-size: 24px; font-weight: bold; color: #10B981; }
        .stat-label { font-size: 12px; color: #888; margin-top: 5px; }
        .slider-group { margin: 15px 0; }
        .slider-group label { display: block; margin-bottom: 5px; color: #a78bfa; }
        input[type="range"] { width: 100%; accent-color: #7C3AED; }
        .value { float: right; color: #888; }
        .q-table { margin-top: 15px; font-size: 10px; }
        .q-row { display: flex; gap: 2px; margin: 2px 0; }
        .q-cell { width: 40px; height: 40px; display: flex; align-items: center; justify-content: center; background: rgba(255,255,255,0.05); border-radius: 4px; }
        .q-cell.agent { background: #7C3AED; }
        .q-cell.goal { background: #10B981; }
        .q-cell.obstacle { background: #EF4444; }
        .episode-log { max-height: 150px; overflow-y: auto; font-size: 11px; color: #888; margin-top: 10px; padding: 10px; background: rgba(0,0,0,0.3); border-radius: 6px; }
        .note { font-size: 12px; color: #888; padding: 10px; background: rgba(0,0,0,0.3); border-radius: 6px; margin-top: 15px; }
    </style>
</head>
<body>
    <a href="index.html" class="back-link">‚Üê Back to ML Gallery</a>
    <h1>Reinforcement Learning Game</h1>
    <p class="subtitle">Watch an AI agent learn to navigate a grid world using Q-Learning</p>

    <div class="container">
        <div class="panel">
            <h3>Grid World</h3>
            <canvas id="grid" width="320" height="320"></canvas>

            <div style="margin-top: 15px;">
                <button onclick="startTraining()" id="trainBtn">üéì Train Agent</button>
                <button onclick="stopTraining()" id="stopBtn" disabled>‚èπÔ∏è Stop</button>
                <button onclick="runEpisode()">‚ñ∂Ô∏è Run Episode</button>
                <button onclick="resetAgent()">üîÑ Reset</button>
            </div>

            <div class="slider-group">
                <label>Learning Rate (Œ±) <span class="value" id="alphaVal">0.1</span></label>
                <input type="range" id="alpha" min="0.01" max="0.5" step="0.01" value="0.1" oninput="updateParams()">
            </div>

            <div class="slider-group">
                <label>Discount Factor (Œ≥) <span class="value" id="gammaVal">0.95</span></label>
                <input type="range" id="gamma" min="0.5" max="0.99" step="0.01" value="0.95" oninput="updateParams()">
            </div>

            <div class="slider-group">
                <label>Exploration (Œµ) <span class="value" id="epsilonVal">0.1</span></label>
                <input type="range" id="epsilon" min="0" max="0.5" step="0.01" value="0.1" oninput="updateParams()">
            </div>

            <div class="slider-group">
                <label>Training Speed <span class="value" id="speedVal">50</span>ms</label>
                <input type="range" id="speed" min="10" max="200" step="10" value="50" oninput="updateParams()">
            </div>
        </div>

        <div class="panel">
            <h3>Training Statistics</h3>
            <div class="stats">
                <div class="stat">
                    <div class="stat-value" id="episodes">0</div>
                    <div class="stat-label">Episodes</div>
                </div>
                <div class="stat">
                    <div class="stat-value" id="steps">0</div>
                    <div class="stat-label">Total Steps</div>
                </div>
                <div class="stat">
                    <div class="stat-value" id="wins">0</div>
                    <div class="stat-label">Wins</div>
                </div>
                <div class="stat">
                    <div class="stat-value" id="avgReward">0</div>
                    <div class="stat-label">Avg Reward</div>
                </div>
            </div>

            <h3 style="margin-top: 20px;">Q-Values Visualization</h3>
            <canvas id="qValues" width="320" height="320"></canvas>

            <div class="episode-log" id="log"></div>

            <div class="note">
                <strong>Legend:</strong> üü£ Agent | üü¢ Goal (+100) | üî¥ Obstacles (-10) | Empty cells (-1 per step<br>
                <strong>Actions:</strong> ‚Üë Up | ‚Üì Down | ‚Üê Left | ‚Üí Right<br>
                The agent learns to find the shortest path to the goal while avoiding obstacles.
            </div>
        </div>
    </div>

    <script>
        const gridCanvas = document.getElementById('grid');
        const gridCtx = gridCanvas.getContext('2d');
        const qCanvas = document.getElementById('qValues');
        const qCtx = qCanvas.getContext('2d');

        const GRID_SIZE = 8;
        const CELL_SIZE = 40;
        const ACTIONS = [[0, -1], [0, 1], [-1, 0], [1, 0]]; // Up, Down, Left, Right
        const ACTION_NAMES = ['‚Üë', '‚Üì', '‚Üê', '‚Üí'];

        let agent = { x: 0, y: 0 };
        let goal = { x: 7, y: 7 };
        let obstacles = [
            { x: 2, y: 2 }, { x: 3, y: 2 }, { x: 4, y: 2 },
            { x: 4, y: 3 }, { x: 4, y: 4 }, { x: 4, y: 5 },
            { x: 5, y: 5 }, { x: 6, y: 5 }
        ];

        // Q-table: state -> action values
        let qTable = {};
        let alpha = 0.1;    // Learning rate
        let gamma = 0.95;   // Discount factor
        let epsilon = 0.1;  // Exploration rate

        let episodeCount = 0;
        let totalSteps = 0;
        let wins = 0;
        let recentRewards = [];
        let training = false;
        let trainingInterval = null;
        let speed = 50;

        function init() {
            resetQTable();
            draw();
            drawQValues();
        }

        function resetQTable() {
            qTable = {};
            for (let x = 0; x < GRID_SIZE; x++) {
                for (let y = 0; y < GRID_SIZE; y++) {
                    const state = `${x},${y}`;
                    qTable[state] = [0, 0, 0, 0]; // Q-values for each action
                }
            }
        }

        function updateParams() {
            alpha = parseFloat(document.getElementById('alpha').value);
            gamma = parseFloat(document.getElementById('gamma').value);
            epsilon = parseFloat(document.getElementById('epsilon').value);
            speed = parseInt(document.getElementById('speed').value);

            document.getElementById('alphaVal').textContent = alpha.toFixed(2);
            document.getElementById('gammaVal').textContent = gamma.toFixed(2);
            document.getElementById('epsilonVal').textContent = epsilon.toFixed(2);
            document.getElementById('speedVal').textContent = speed;
        }

        function getState(x, y) {
            return `${x},${y}`;
        }

        function isValidPosition(x, y) {
            return x >= 0 && x < GRID_SIZE && y >= 0 && y < GRID_SIZE;
        }

        function isObstacle(x, y) {
            return obstacles.some(o => o.x === x && o.y === y);
        }

        function isGoal(x, y) {
            return x === goal.x && y === goal.y;
        }

        function getReward(x, y) {
            if (isGoal(x, y)) return 100;
            if (isObstacle(x, y)) return -10;
            return -1; // Small penalty for each step
        }

        function chooseAction(state) {
            // Epsilon-greedy policy
            if (Math.random() < epsilon) {
                return Math.floor(Math.random() * 4);
            }

            const qValues = qTable[state];
            const maxQ = Math.max(...qValues);
            const bestActions = qValues.map((q, i) => q === maxQ ? i : -1).filter(i => i >= 0);
            return bestActions[Math.floor(Math.random() * bestActions.length)];
        }

        function takeAction(action) {
            const [dx, dy] = ACTIONS[action];
            let newX = agent.x + dx;
            let newY = agent.y + dy;

            // Boundary check
            if (!isValidPosition(newX, newY)) {
                newX = agent.x;
                newY = agent.y;
            }

            const reward = getReward(newX, newY);

            // Q-Learning update
            const state = getState(agent.x, agent.y);
            const newState = getState(newX, newY);
            const oldQ = qTable[state][action];
            const maxNextQ = Math.max(...qTable[newState]);
            const newQ = oldQ + alpha * (reward + gamma * maxNextQ - oldQ);
            qTable[state][action] = newQ;

            agent.x = newX;
            agent.y = newY;

            return { reward, done: isGoal(newX, newY) || isObstacle(newX, newY) };
        }

        function runEpisode(visualize = true) {
            agent = { x: 0, y: 0 };
            let totalReward = 0;
            let steps = 0;
            const maxSteps = 100;

            const stepFn = () => {
                if (steps >= maxSteps) {
                    finishEpisode(totalReward, false);
                    return;
                }

                const state = getState(agent.x, agent.y);
                const action = chooseAction(state);
                const { reward, done } = takeAction(action);

                totalReward += reward;
                steps++;
                totalSteps++;

                if (visualize) {
                    draw();
                    drawQValues();
                }

                if (done) {
                    finishEpisode(totalReward, isGoal(agent.x, agent.y));
                } else if (visualize) {
                    setTimeout(stepFn, speed);
                } else {
                    stepFn();
                }
            };

            if (visualize) {
                stepFn();
            } else {
                while (steps < maxSteps) {
                    const state = getState(agent.x, agent.y);
                    const action = chooseAction(state);
                    const { reward, done } = takeAction(action);
                    totalReward += reward;
                    steps++;
                    totalSteps++;
                    if (done) break;
                }
                finishEpisode(totalReward, isGoal(agent.x, agent.y));
            }
        }

        function finishEpisode(totalReward, won) {
            episodeCount++;
            if (won) wins++;

            recentRewards.push(totalReward);
            if (recentRewards.length > 100) recentRewards.shift();

            updateStats();
            log(`Episode ${episodeCount}: ${won ? '‚úÖ Won' : '‚ùå Failed'} | Reward: ${totalReward.toFixed(0)}`);

            if (training) {
                agent = { x: 0, y: 0 };
            }
        }

        function updateStats() {
            document.getElementById('episodes').textContent = episodeCount;
            document.getElementById('steps').textContent = totalSteps;
            document.getElementById('wins').textContent = wins;

            const avg = recentRewards.length > 0
                ? (recentRewards.reduce((a, b) => a + b, 0) / recentRewards.length).toFixed(1)
                : 0;
            document.getElementById('avgReward').textContent = avg;
        }

        function startTraining() {
            training = true;
            document.getElementById('trainBtn').disabled = true;
            document.getElementById('stopBtn').disabled = false;

            trainingInterval = setInterval(() => {
                runEpisode(false);
                draw();
                drawQValues();
            }, 10);
        }

        function stopTraining() {
            training = false;
            clearInterval(trainingInterval);
            document.getElementById('trainBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
        }

        function resetAgent() {
            stopTraining();
            agent = { x: 0, y: 0 };
            episodeCount = 0;
            totalSteps = 0;
            wins = 0;
            recentRewards = [];
            resetQTable();
            updateStats();
            draw();
            drawQValues();
            document.getElementById('log').innerHTML = '';
        }

        function log(message) {
            const logEl = document.getElementById('log');
            logEl.innerHTML = message + '<br>' + logEl.innerHTML;
            if (logEl.children.length > 50) {
                logEl.innerHTML = logEl.innerHTML.split('<br>').slice(0, 50).join('<br>');
            }
        }

        function draw() {
            gridCtx.fillStyle = '#1a1a2e';
            gridCtx.fillRect(0, 0, gridCanvas.width, gridCanvas.height);

            // Draw grid
            for (let x = 0; x < GRID_SIZE; x++) {
                for (let y = 0; y < GRID_SIZE; y++) {
                    const px = x * CELL_SIZE;
                    const py = y * CELL_SIZE;

                    // Cell background
                    if (isGoal(x, y)) {
                        gridCtx.fillStyle = 'rgba(16, 185, 129, 0.3)';
                    } else if (isObstacle(x, y)) {
                        gridCtx.fillStyle = 'rgba(239, 68, 68, 0.3)';
                    } else {
                        gridCtx.fillStyle = 'rgba(255, 255, 255, 0.05)';
                    }
                    gridCtx.fillRect(px + 1, py + 1, CELL_SIZE - 2, CELL_SIZE - 2);

                    // Grid lines
                    gridCtx.strokeStyle = 'rgba(255, 255, 255, 0.1)';
                    gridCtx.strokeRect(px, py, CELL_SIZE, CELL_SIZE);
                }
            }

            // Draw obstacles
            obstacles.forEach(o => {
                gridCtx.fillStyle = '#EF4444';
                gridCtx.beginPath();
                gridCtx.arc(o.x * CELL_SIZE + CELL_SIZE / 2, o.y * CELL_SIZE + CELL_SIZE / 2, CELL_SIZE / 3, 0, Math.PI * 2);
                gridCtx.fill();
            });

            // Draw goal
            gridCtx.fillStyle = '#10B981';
            gridCtx.beginPath();
            gridCtx.arc(goal.x * CELL_SIZE + CELL_SIZE / 2, goal.y * CELL_SIZE + CELL_SIZE / 2, CELL_SIZE / 3, 0, Math.PI * 2);
            gridCtx.fill();

            // Draw agent
            gridCtx.fillStyle = '#7C3AED';
            gridCtx.beginPath();
            gridCtx.arc(agent.x * CELL_SIZE + CELL_SIZE / 2, agent.y * CELL_SIZE + CELL_SIZE / 2, CELL_SIZE / 3, 0, Math.PI * 2);
            gridCtx.fill();
            gridCtx.strokeStyle = 'white';
            gridCtx.lineWidth = 2;
            gridCtx.stroke();
        }

        function drawQValues() {
            qCtx.fillStyle = '#1a1a2e';
            qCtx.fillRect(0, 0, qCanvas.width, qCanvas.height);

            for (let x = 0; x < GRID_SIZE; x++) {
                for (let y = 0; y < GRID_SIZE; y++) {
                    const px = x * CELL_SIZE;
                    const py = y * CELL_SIZE;
                    const state = getState(x, y);
                    const qValues = qTable[state];

                    // Find best action
                    const maxQ = Math.max(...qValues);
                    const minQ = Math.min(...qValues);
                    const range = maxQ - minQ || 1;

                    // Draw arrows for each action with color based on Q-value
                    for (let a = 0; a < 4; a++) {
                        const [dx, dy] = ACTIONS[a];
                        const q = qValues[a];
                        const intensity = (q - minQ) / range;

                        // Color: red (bad) to green (good)
                        const r = Math.floor(255 * (1 - intensity));
                        const g = Math.floor(255 * intensity);
                        qCtx.fillStyle = `rgb(${r}, ${g}, 100)`;

                        const cx = px + CELL_SIZE / 2;
                        const cy = py + CELL_SIZE / 2;

                        // Draw small triangle pointing in action direction
                        qCtx.beginPath();
                        const size = 8;
                        const offset = 12;
                        const ax = cx + dx * offset;
                        const ay = cy + dy * offset;

                        if (a === 0) { // Up
                            qCtx.moveTo(ax, ay - size);
                            qCtx.lineTo(ax - size / 2, ay);
                            qCtx.lineTo(ax + size / 2, ay);
                        } else if (a === 1) { // Down
                            qCtx.moveTo(ax, ay + size);
                            qCtx.lineTo(ax - size / 2, ay);
                            qCtx.lineTo(ax + size / 2, ay);
                        } else if (a === 2) { // Left
                            qCtx.moveTo(ax - size, ay);
                            qCtx.lineTo(ax, ay - size / 2);
                            qCtx.lineTo(ax, ay + size / 2);
                        } else { // Right
                            qCtx.moveTo(ax + size, ay);
                            qCtx.lineTo(ax, ay - size / 2);
                            qCtx.lineTo(ax, ay + size / 2);
                        }
                        qCtx.closePath();
                        qCtx.fill();
                    }

                    // Draw grid lines
                    qCtx.strokeStyle = 'rgba(255, 255, 255, 0.1)';
                    qCtx.strokeRect(px, py, CELL_SIZE, CELL_SIZE);
                }
            }
        }

        init();
    </script>
</body>
</html>
