<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Morphing Waveform</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            display: flex;
            align-items: center;
            justify-content: center;
            height: 100vh;
        }
        canvas { display: block; }
        .controls {
            position: absolute;
            top: 20px;
            left: 20px;
            color: white;
            background: rgba(0, 0, 0, 0.7);
            padding: 15px;
            border-radius: 10px;
        }
        button {
            background: #764ba2;
            color: white;
            border: none;
            padding: 10px 20px;
            margin: 5px;
            cursor: pointer;
            border-radius: 5px;
        }
        button:hover { background: #5E3A7F; }
        input[type="file"] { margin: 10px 0; }
    </style>
</head>
<body>
    <div class="controls">
        <h2>Morphing Waveform</h2>
        <input type="file" id="audioFile" accept="audio/*">
        <br>
        <button id="playBtn">Play</button>
        <button id="pauseBtn">Pause</button>
    </div>
    <canvas id="canvas"></canvas>

    <script>
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        canvas.width = window.innerWidth;
        canvas.height = window.innerHeight;

        let audioContext, analyser, dataArray, bufferLength, source, audio;
        let morphState = 0;

        document.getElementById('audioFile').addEventListener('change', function(e) {
            const file = e.target.files[0];
            if (file) initAudio(URL.createObjectURL(file));
        });

        document.getElementById('playBtn').addEventListener('click', () => {
            if (audio) {
                audio.play();
                if (!audioContext) setupAudioContext();
                visualize();
            }
        });

        document.getElementById('pauseBtn').addEventListener('click', () => {
            if (audio) audio.pause();
        });

        function initAudio(url) {
            if (audio) audio.pause();
            audio = new Audio(url);
            audio.loop = true;
            if (!audioContext) {
                setupAudioContext();
            } else {
                if (source) source.disconnect();
                source = audioContext.createMediaElementSource(audio);
                source.connect(analyser);
                analyser.connect(audioContext.destination);
            }
        }

        function setupAudioContext() {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 1024;
            bufferLength = analyser.frequencyBinCount;
            dataArray = new Uint8Array(bufferLength);

            if (audio) {
                source = audioContext.createMediaElementSource(audio);
                source.connect(analyser);
                analyser.connect(audioContext.destination);
            }
        }

        function visualize() {
            requestAnimationFrame(visualize);
            analyser.getByteTimeDomainData(dataArray);

            ctx.fillStyle = 'rgba(102, 126, 234, 0.1)';
            ctx.fillRect(0, 0, canvas.width, canvas.height);

            morphState += 0.02;

            // Calculate average amplitude for morphing
            const avg = dataArray.reduce((a, b) => a + b) / bufferLength;
            const morphFactor = Math.sin(morphState) * 0.5 + 0.5;

            const centerY = canvas.height / 2;
            const sliceWidth = canvas.width / bufferLength;

            // Draw multiple morphing layers
            for (let layer = 0; layer < 3; layer++) {
                ctx.strokeStyle = `rgba(255, 255, 255, ${0.5 - layer * 0.15})`;
                ctx.lineWidth = 3 - layer;
                ctx.shadowBlur = 10;
                ctx.shadowColor = 'rgba(255, 255, 255, 0.5)';
                ctx.beginPath();

                let x = 0;
                for (let i = 0; i < bufferLength; i++) {
                    const v = dataArray[i] / 128.0;
                    const baseY = v * centerY;

                    // Apply morphing effect
                    const waveY = baseY + Math.sin(i * 0.1 + morphState + layer) * 30 * morphFactor;
                    const y = waveY;

                    if (i === 0) {
                        ctx.moveTo(x, y);
                    } else {
                        ctx.lineTo(x, y);
                    }

                    x += sliceWidth;
                }

                ctx.stroke();
            }

            ctx.shadowBlur = 0;
        }

        window.addEventListener('load', () => {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 1024;
            bufferLength = analyser.frequencyBinCount;
            dataArray = new Uint8Array(bufferLength);

            const oscillator = audioContext.createOscillator();
            const gain = audioContext.createGain();
            oscillator.connect(gain);
            gain.connect(analyser);
            analyser.connect(audioContext.destination);
            oscillator.frequency.value = 440;
            gain.gain.value = 0.1;
            oscillator.start();

            visualize();
        });

        // Expose for enhance.js
        window.reset = function() { ctx.clearRect(0, 0, canvas.width, canvas.height); };

        window.addEventListener('resize', () => {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
        });
    </script>
    <script src="../../assets/js/enhance.js" defer></script>
</body>
</html>
